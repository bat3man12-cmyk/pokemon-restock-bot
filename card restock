import os
import requests
from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim
from geopy.distance import geodesic

# ================= CONFIG =================

DISCORD_WEBHOOK = os.getenv("DISCORD_WEBHOOK")
USER_POSTCODE = "DN9"
MAX_DISTANCE_MILES = 30

HEADERS = {
    "User-Agent": "Mozilla/5.0 (PokemonRestockChecker/1.0)"
}

if not DISCORD_WEBHOOK:
    raise RuntimeError("DISCORD_WEBHOOK missing")

# ================= LOCATION =================

geolocator = Nominatim(user_agent="pokemon_checker")
location = geolocator.geocode(USER_POSTCODE)

if not location:
    raise RuntimeError("Postcode lookup failed")

USER_COORD = (location.latitude, location.longitude)

# ================= KEYWORDS =================

SEALED_KEYWORDS = [
    "booster",
    "elite trainer box",
    "etb",
    "tin",
    "collection",
    "blister",
    "trading card",
]

IGNORE_KEYWORDS = [
    "single",
    "guide",
    "book",
    "magazine",
    "proxy",
]

# ================= HELPERS =================

def is_sealed(name: str) -> bool:
    name = name.lower()
    return any(k in name for k in SEALED_KEYWORDS) and not any(
        i in name for i in IGNORE_KEYWORDS
    )

def within_distance(coord):
    return geodesic(USER_COORD, coord).miles <= MAX_DISTANCE_MILES

def send_discord(message: str):
    requests.post(DISCORD_WEBHOOK, json={"content": message}, timeout=10)

def get_soup(url):
    r = requests.get(url, headers=HEADERS, timeout=20)
    return BeautifulSoup(r.text, "html.parser")

# ================= PER-STORE PARSERS =================

def parse_smyths(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("h2.product-name")
        if is_sealed(p.get_text())
    ]

def parse_entertainer(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("a.product-name")
        if is_sealed(p.get_text())
    ]

def parse_argos(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("div[data-test='component-product-card-title']")
        if is_sealed(p.get_text())
    ]

def parse_whsmith(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("h3")
        if is_sealed(p.get_text())
    ]

def parse_forbidden_planet(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("h3.product-title")
        if is_sealed(p.get_text())
    ]

def parse_waterstones(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("a.title")
        if is_sealed(p.get_text())
    ]

def parse_cex(url):
    soup = get_soup(url)
    return [
        p.get_text(strip=True)
        for p in soup.select("h3")
        if is_sealed(p.get_text())
    ]

def generic_parser(url):
    soup = get_soup(_
